{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b756a4bd",
   "metadata": {},
   "source": [
    "# DDFA module 8, capstone option #1\n",
    "\n",
    "For your last module, you're going to be building your own model, from scratch! But don't worry, you'll be getting a _little_ bit of help: you have three options of datasets to choose from (plus, you can of course always ask any questions of the TA). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a387d",
   "metadata": {},
   "source": [
    "## Option 1: Credit risk modeling (probability of default)\n",
    "\n",
    "If you choose this option, you will be building a [probability of default](https://www.investopedia.com/terms/d/defaultprobability.asp) model. We'll be using publicly available data from Kaggle (a data science competition website with freely available datasets, and even some competitions for money! Check it out). \n",
    "\n",
    "**Probability of default** is one type of model used in **[credit risk modeling](https://corporatefinanceinstitute.com/resources/knowledge/credit/credit-risk-analysis-models/)**. There are generally three types of models used in basic credit risk modeling: \n",
    "\n",
    "1. Probability of default (PD): the likelihood that a borrower (individual or institution) will default on a loan in a set amount of time in the future. E.g. PD within the next 6 months. \n",
    "2. Loss given default (LGD): this represents the amount a lender will lose if a borrower defaults. This is a more complex calculation and takes into account how long into a loan a borrower may default. \n",
    "3. Expsoure at default (EAD): the amount of possible loss a lender is exposed to at any given time. Generally, EAD = PD x LGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d90569",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "You'll be using a dataset on 250,000 borrowers put together by Kaggle. You can read more about the dataset [here](https://www.kaggle.com/c/GiveMeSomeCredit/overview). Rather than downloading the data from Kaggle, please use the provided dataset as some small fixes have been applied to it. There are two files: \n",
    "\n",
    "* credit_risk_PD.csv: this is your data on the 250,000 borrowers. You'll need to split it into train/test sets. The dependent variable (outcome variable) is the column called `SeriousDlqin2yrs`\n",
    "* credit_risk_PD-data-dictionary.xlsx: the data dictionary that describes what each column is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c65f1a6",
   "metadata": {},
   "source": [
    "## Your assignment\n",
    "\n",
    "You should import the csv dataset mentioned above. You'll then want to carry out an entire end-to-end data science workflow. This includes: \n",
    "\n",
    "* Import the data\n",
    "* Explore the data using summary tables and charts/graphs (use `matplotlib` and `Pandas`, such as the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) method)\n",
    "* Transform the data if necessary using `Pandas` \n",
    "* Train/test split the data (optional but recommended) \n",
    "* Apply at least one machine learning algorithm to the dataset (e.g. logistic regression)\n",
    "* Check how well your model is working (e.g. R^2 for linear regression or accuracy/precision/recall for classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cb4fe",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "Your mission, should you choose to accept it, is to use the provided dataset to build a probability of default model. Here are some things you should know: \n",
    "\n",
    "* The outcome variable, `SeriousDlqin2yrs`, is a binary (that is, can take on values of 0 or 1)\n",
    "* Think about the types of algorithms that work well for binary outcomes (e.g. logistic regression, perhaps?)\n",
    "* If there are any categorical features in your dataset, how can you change them to use them in your model? (hint: dummy variables) \n",
    "* Remember to use train/test split\n",
    "* If you'd like to challenge yourself, use a k-fold cross validation\n",
    "* Are the classes balanced? If not, what can you do to rebalance them? (hint: revisit instructor webinar 3, if needed)\n",
    "* Kaggle allows users to post their solution notebooks to the site for each dataset, and it's perfectly fine to [check out others' solutions for inspiration](https://www.kaggle.com/c/GiveMeSomeCredit/code) as you work on your own solution. Of course, you can't just copy/paste others' work and claim it as your own! Don't cheat, but you can take hints if you're stuck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d021c56",
   "metadata": {},
   "source": [
    "## Get started! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4630220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57afedea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the data and doing some Exploratory Data Analysis\n",
    "df_train = pd.read_csv('./credit_risk_PD_train.csv')\n",
    "df_test = pd.read_csv('./credit_risk_PD_test.csv')\n",
    "df_train.shape\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab90c6",
   "metadata": {},
   "source": [
    "We see that there are no classes, so the there is no need to use dummy variables in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing the ones with SeriousDlqin2yrs equal to 1:\n",
    "df_train[df_train['SeriousDlqin2yrs'] == 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d85a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing the ones with SeriousDlqin2yrs equal to 1:\n",
    "df_train[df_train['SeriousDlqin2yrs'] == 1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285e9db",
   "metadata": {},
   "source": [
    "**Conclusions**: Data looks promising in a certain way. We can see customers with a Serious Delinquency in 2 years compared to others with no Delinquency by their mean values:<br>\n",
    "\n",
    "**SeriousDlqin2yrs : 0 | 1**<br>\n",
    "RevolvingUtilizationOfUnsecuredLines : 6.16 | 4.36; std: 256|131<br>\n",
    "age : 52 | 45; std: 14|12<br>\n",
    "**NumberOfTime30-59DaysPastDueNotWorse : 0.28 | 2.38; std: 2.9|11.7**<br>\n",
    "DebtRatio : 357.15 | 295.12; std: 2,038|1,238<br>\n",
    "MonthlyIncome : 5395 | 4,693; std: 13,518|6,012<br>\n",
    "NumberOfOpenCreditLinesAndLoans : 8.5| 7.8; std: 5.1|5.6<br>\n",
    "**NumberOfTimes90DaysLate : 0.13 | 2.09; std: 2.9|11.7**<br>\n",
    "**NumberRealEstateLoansOrLines : 1.02 | 1.82; std: 1.1|1.4**<br>\n",
    "**NumberOfTime60-89DaysPastDueNotWorse : 0.12 | 1.82; std: 2.9|11.7**<br>\n",
    "NumberOfDependents : 0.74 | 0.94; std: 1|1.2<br>\n",
    "\n",
    "Some insights can be get from this direct comparison:\n",
    "\n",
    "- NumberOfTime30-59DaysPastDueNotWorse, NumberOfTime60-89DaysPastDueNotWorse and NumberOfTimes90DaysLate have significant higher average values to deafaut clients compared to non-default one;\n",
    "\n",
    "- Significant standard deviation values for those variables may indicate the existance of outliers;\n",
    "\n",
    "- Possible profile of \"default clients\": slightly younger, with more dependents and smaller monthly income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f8493",
   "metadata": {},
   "source": [
    "*Histograms:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da15d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a00f208c3f43dbab2e6107f71ad9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |                                             | [  0%]   00:00 ->â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_report = sweetviz.analyze([df_train, 'Train'],target_feat = 'SeriousDlqin2yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60beafba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report EDA_credit_analysis.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "my_report.show_html('EDA_credit_analysis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a76a8",
   "metadata": {},
   "source": [
    "*Heatmaps for correlation:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_train.corr(),vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34346294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7cc45",
   "metadata": {},
   "source": [
    "Taking into account that for the NumberOfDependents only about 3% are null and that normally the absence of values in this situation could indicate the lack of dependents, it seems reasonable to complete the null values with zero.\n",
    "A similar approach could be followed for the MonthlyIncome, as it is possible that people could have no income we could set this value to zero. Other alternative could be drop the lines, but considering we are talking about 30 thousands lines, we could lose revelant information in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b1878",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Preprocessing pipeline\n",
    " preprocessing = Pipeline([\n",
    "    ('Fill_na', SimpleImputer(strategy='constant',fill_value=0)),\n",
    "    ('Outlier_Scaling', RobustScaler())\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a51c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a list of binary classification models considered\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_features='auto', bootstrap=True, max_samples=2/3)\n",
    "log_reg = LogisticRegression(solver= 'liblinear', C=1000, random_state=42)\n",
    "\n",
    "#Define a model list to iterate\n",
    "model_list = [random_forest,log_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate each model to define the best through cross validation\n",
    "for model_classifier in model_list:\n",
    "\n",
    " #Pipeline with model\n",
    " pipe_model = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('classifier', model_classifier)\n",
    " ])\n",
    "\n",
    " #Parameter grid\n",
    "\n",
    " if model_classifier == random_forest:\n",
    "     param_grid= [\n",
    "    {'classifier__max_features' :['auto','log2',1/3, 2/3, 1],'classifier__max_samples': [1/3, 2/3, 1]}\n",
    "             ]\n",
    " else: \n",
    "     param_grid = [\n",
    "    {'classifier__C' :[10,100,1000],'classifier__class_weight': [None, 'dict', 'balanced']}\n",
    "             ]\n",
    "\n",
    "    \n",
    " #CV and grid search\n",
    " grid = GridSearchCV(estimator = pipe_model, param_grid = param_grid, cv = 5, scoring= 'roc_auc')\n",
    "\n",
    " #Define X and y\n",
    " X = df_train.drop(columns=['Unnamed: 0','SeriousDlqin2yrs'])\n",
    " y = df_train['SeriousDlqin2yrs']\n",
    "\n",
    " #Fit and score\n",
    " grid.fit(X, y)\n",
    " print(model_classifier)\n",
    " print('Best score: ', grid.best_score_)\n",
    " print('Best parameter: ',grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cefbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Unnamed: 0','SeriousDlqin2yrs'])\n",
    "y = df['SeriousDlqin2yrs']\n",
    "\n",
    "#20% of the data will be hold out to test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "#Class Prediction for probability and binary\n",
    "class_prediction_proba = random_forest.predict_proba(X_test)\n",
    "class_prediction = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_info(random_forest, X_test, y_test, class_prediction, class_prediction_proba):\n",
    "    #'''This function returns the critical information about the model'''\n",
    "#pretty version of the above confusion matrix \n",
    " conf_m = pd.DataFrame(confusion_matrix(y_test, class_prediction))\n",
    " conf_m.index = ['Actual Non-default (0)','Actual Default (1)']\n",
    " conf_m.columns = ['Predict Non-default (0)', 'Predict Default (1)']\n",
    " print(conf_m,'\\n')\n",
    " tn, fp, fn, tp = conf_m.to_numpy().ravel()\n",
    "\n",
    "#AUC roc score\n",
    " class_prediction_auc = roc_auc_score(y_true =y_test[:], y_score =class_prediction_proba[:,1])\n",
    " print(f'The auc scores of our model is {class_prediction_auc:.3f}.')\n",
    "\n",
    "#Accuracy Score\n",
    " score = random_forest.score(X_test, y_test)\n",
    " print(f'The accuracy of our model is {score*100:.3f}%.')\n",
    "\n",
    "#Precision and recall\n",
    " score_precision = tp/(tp + fp)\n",
    " print(f'The precision of our model is {score_precision*100:.3f}%.')\n",
    " score_recall = tp/(tp + fn)\n",
    " print(f'The recall of our model is {score_recall*100:.3f}%.')\n",
    "\n",
    "#LR model Roc Curve\n",
    " fpr, tpr, thresholds  = roc_curve(y_true =y_test[:], y_score =class_prediction_proba[:,1])\n",
    "    \n",
    "#No Skill model\n",
    " fpr_ns = np.linspace(0,1,num=len(fpr))\n",
    " trp_ns = fpr_ns\n",
    "\n",
    "#Plotting ROC Curve\n",
    " plt.plot(fpr_ns, trp_ns, linestyle='dashed',label='No Skill')\n",
    " plt.plot(fpr, tpr,label='Lr model')\n",
    "#Labels\n",
    " plt.title('ROC curve')\n",
    " plt.xlabel('False Positive Rate')\n",
    " plt.ylabel('True Positive Rate')\n",
    "#Legend\n",
    " plt.legend()\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79595195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info(random_forest, X_test, y_test, class_prediction, class_prediction_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a586c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'max_features' :['auto','log2',1/3 ,2/3, 1], 'max_samples': [1/3, 2/3, 1]}\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator = random_forest, param_grid = param_grid, cv = 5, scoring= 'roc_auc')\n",
    "#Grid Search to parameter tuning\n",
    "#Cross validate to find the best one\n",
    "#Calculate a pre-defined score for each interaction (like roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74797a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y)\n",
    "print('Best score: ', grid.best_score_)\n",
    "print('Best parameter: ',grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d83e7",
   "metadata": {},
   "source": [
    "**From the data we see a low recall, which means our model is insensitive to classify dafault-cases**\n",
    "Maybe the \"default data\" and \"non-default data\" look too similar to the model.\n",
    "\n",
    "**Possible Solution**: less try to make the dataset more homogeneous removing outliers. We'll use the interquatile distance method for outliers, one of the most acknowledged.\n",
    "\n",
    "However, the approach followed was to remove outliers separated for the Default data and Non-default data. This is important since what we aim to achieve is to make each subset more **homogeneous between themselves** but **more different compared to each other**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c93f36e",
   "metadata": {},
   "source": [
    "Since we plan to remove outliers to better train our model, it is important that the tests are performed in a subset **without** the outliers removal, or we will not be able to catch a glimpse of the real model's performance.\n",
    "<br>So,<br>\n",
    "train subset: without outliers <br>\n",
    "test subset: with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcbebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So 20% of the model will be separated to tests.\n",
    "#Considering the approach follow the 'SeriousDlqin2yrs' will be necessary now, so it will stay in X just for now\n",
    "#So before fitting the model we are going to drop it\n",
    "X = df.drop(columns=['Unnamed: 0'])\n",
    "y = df['SeriousDlqin2yrs']\n",
    "\n",
    "#20% of the data will be hold out to test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf299a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shapes obtained:\n",
    "print('X:',X.shape)\n",
    "print('y:',y.shape)\n",
    "print('X_test:',X_test.shape)\n",
    "print('y_test:',y_test.shape)\n",
    "print('X:',X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ba55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers removal\n",
    "#Default subset. Since we select ['SeriousDlqin2yrs'] == 1] we need it in X (just for now)\n",
    "X_train_dflt_full = X_train[X_train['SeriousDlqin2yrs'] == 1]\n",
    "X_train_dflt = X_train_dflt_full\n",
    "\n",
    "#Here we chosse the \"i_th\" variable to be removed. i=0 is the SeriousDlqin2yrs (target varible), which is ignored.\n",
    "for i in [1,2,3,4,5,6,7,8,9,10]:\n",
    " print(X_train_dflt_full.columns[i])\n",
    "\n",
    "#Q1,Q3,interquartile defined regarding the full dataset\n",
    " Q1 = X_train_dflt_full[X_train_dflt_full.columns[i]].quantile(0.25)\n",
    " Q3 = X_train_dflt_full[X_train_dflt_full.columns[i]].quantile(0.75)\n",
    " Interquartil = Q3 - Q1\n",
    " lower_bound = Q1 - 1.5*Interquartil\n",
    " upper_bound = Q3 + 1.5*Interquartil\n",
    "\n",
    "#data smaller than the lower bound and greater than the upper bound will be removed. \n",
    " X_train_dflt = X_train_dflt[(X_train_dflt[X_train_dflt.columns[i]] >= lower_bound) & (X_train_dflt[X_train_dflt.columns[i]] <= upper_bound)]\n",
    " print (\"i: \", i)\n",
    " print('q1: ',Q1,'q3: ',Q3,'lb: ',lower_bound,'ub: ',upper_bound)\n",
    " print(len(X_train_dflt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f495190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outliers e visualization\n",
    "#Non-Default subset\n",
    "X_train_nodflt_full = X_train[X_train['SeriousDlqin2yrs'] == 0]\n",
    "X_train_nodflt = X_train_nodflt_full\n",
    "\n",
    "#Here we chosse the \"i_th\" variable to be removed. i=0 is the SeriousDlqin2yrs (target varible), which is ignored.\n",
    "for i in [1,2,3,4,5,6,7,8,9,10]:\n",
    " print(X_train_nodflt_full.columns[i])\n",
    "\n",
    "#Q1,Q3,interquartile defined regarding the full dataset\n",
    " Q1 = X_train_nodflt_full[X_train_nodflt_full.columns[i]].quantile(0.25)\n",
    " Q3 = X_train_nodflt_full[X_train_nodflt_full.columns[i]].quantile(0.75)\n",
    " Interquartil = Q3 - Q1\n",
    " lower_bound = Q1 - 1.5*Interquartil\n",
    " upper_bound = Q3 + 1.5*Interquartil\n",
    "\n",
    "#data smaller than the lower bound and greater than the upper bound will be removed.  \n",
    " X_train_nodflt = X_train_nodflt[(X_train_nodflt[X_train_nodflt.columns[i]] >= lower_bound) & (X_train_nodflt[X_train_nodflt.columns[i]] <= upper_bound)]\n",
    " print (\"i: \", i)\n",
    " print('q1: ',Q1,'q3: ',Q3,'lb: ',lower_bound,'ub: ',upper_bound)\n",
    " print(len(X_train_nodflt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate frames to restore the total dataset composed by default and non-default data\n",
    "frames = [X_train_dflt,X_train_nodflt]\n",
    "X_train_new = pd.concat(frames)\n",
    "\n",
    "#Prepare the final default set\n",
    "y_train_new = X_train_new['SeriousDlqin2yrs']\n",
    "X_train_new = X_train_new.drop(columns=['SeriousDlqin2yrs'])\n",
    "X_test = X_test.drop(columns=['SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77072211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shapes obtained:\n",
    "print('X_train_new:',X_train_new.shape)\n",
    "print('y_train_new:',y_train_new.shape)\n",
    "print('X_train_new:',X_train_new.columns)\n",
    "print('X_test:',X_test.shape)\n",
    "print('y_test:',y_test.shape)\n",
    "print('X_test:',X_test.shape)\n",
    "print('X_test:',X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b018cb2",
   "metadata": {},
   "source": [
    "**Confusion Matrix** - Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a Regression Logistic model\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_features='auto', bootstrap=True, max_samples=None)\n",
    "random_forest.fit(X = X_train_new, y = y_train_new)\n",
    "\n",
    "#Class Prediction for probability and binary\n",
    "class_prediction_proba = random_forest.predict_proba(X_train_new)\n",
    "class_prediction = random_forest.predict(X_train_new)\n",
    "\n",
    "model_info(random_forest, X_test = X_train_new,  y_test= y_train_new,  class_prediction = class_prediction, class_prediction_proba = class_prediction_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d8794",
   "metadata": {},
   "source": [
    "**Confusion Matrix** - Test dataset (without outliers removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a093ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit a Regression Logistic model to test dataset\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_features='auto', bootstrap=True, max_samples=None)\n",
    "random_forest.fit(X = X_train_new, y = y_train_new)\n",
    "\n",
    "#Class Prediction for probability and binary\n",
    "class_prediction_proba = random_forest.predict_proba(X_test)\n",
    "class_prediction = random_forest.predict(X_test)\n",
    "\n",
    "model_info(random_forest, X_test = X_test,  y_test= y_test, class_prediction = class_prediction,class_prediction_proba = class_prediction_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
